{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83536b6b-6fcc-47fb-b54f-41830d8152ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando os arquivos tsv para processamento e exportação no formato parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2200495c-b75c-4409-8f08-4e39335774ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 21:16:57 WARN Utils: Your hostname, DESKTOP-TCH95BD resolves to a loopback address: 127.0.1.1; using 172.20.29.145 instead (on interface eth0)\n",
      "23/11/01 21:16:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/01 21:17:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39264e-35d9-4300-9731-da5e66b8d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivos Tsv e criando dfs, usando delimitador /t e header true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489bb7f-b86a-427c-8d49-0b1b7bc87302",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicos_filmes = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_basic.tsv\")\n",
    "diretor_escritor = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_crew.tsv\")\n",
    "filmes_principais = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_principal.tsv\")\n",
    "filmes_votos = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_rating.tsv\")\n",
    "nome_colaboradores = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/name.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a8d1f-586c-4103-b13e-9acc62dbd6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7c75f-45e0-4bcf-bd18-a77585362913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo arquivos e criando o df basicos_filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3900cf9-7e21-4ae4-9a97-13798ed0b5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1df6871-366b-447a-9e59-8454dc0da040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      " |-- runtimeMinutes: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|     \\N|             1|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|     \\N|             5|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|     \\N|             4|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|     \\N|            12|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|     \\N|             1|        Comedy,Short|\n",
      "|tt0000006|    short|   Chinese Opium Den|   Chinese Opium Den|      0|     1894|     \\N|             1|               Short|\n",
      "|tt0000007|    short|Corbett and Court...|Corbett and Court...|      0|     1894|     \\N|             1|         Short,Sport|\n",
      "|tt0000008|    short|Edison Kinetoscop...|Edison Kinetoscop...|      0|     1894|     \\N|             1|   Documentary,Short|\n",
      "|tt0000009|    movie|          Miss Jerry|          Miss Jerry|      0|     1894|     \\N|            45|             Romance|\n",
      "|tt0000010|    short| Leaving the Factory|La sortie de l'us...|      0|     1895|     \\N|             1|   Documentary,Short|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 9 colunas.\n",
      "O DataFrame tem 10265844 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "basicos_filmes = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_basic.tsv\")\n",
    "basicos_filmes.printSchema()\n",
    "basicos_filmes.show(10)\n",
    "contagem_de_dados = basicos_filmes.count()\n",
    "contagem_de_colunas = len(basicos_filmes.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550c0c6-bf78-4b95-bb1e-90c522e90f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No campo tipo, contém filmes, curtas... vou trabalhar apenas com o valor MOVIE\n",
    "# Agora, alterando o nome das colunas e filtrando o gênero que contém apenas DRAMA, pois não utilizarei Romance.\n",
    "# Pelo fato de ter escolhido o Diretor Martin Scorsese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a76748-1229-4210-a4df-5a94109a5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o nome das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56c2173-3ff2-4199-b1ed-438b9535df19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_filme: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- titulo: string (nullable = true)\n",
      " |-- titulo_original: string (nullable = true)\n",
      " |-- adulto: string (nullable = true)\n",
      " |-- lancamento: string (nullable = true)\n",
      " |-- fim_lancamento: string (nullable = true)\n",
      " |-- duracao_filme: string (nullable = true)\n",
      " |-- genero: string (nullable = true)\n",
      "\n",
      "+---------+-----+--------------------+--------------------+------+----------+--------------+-------------+---------------+\n",
      "| id_filme| tipo|              titulo|     titulo_original|adulto|lancamento|fim_lancamento|duracao_filme|         genero|\n",
      "+---------+-----+--------------------+--------------------+------+----------+--------------+-------------+---------------+\n",
      "|tt0000591|movie|    The Prodigal Son|   L'enfant prodigue|     0|      1907|            \\N|           90|          Drama|\n",
      "|tt0000615|movie|  Robbery Under Arms|  Robbery Under Arms|     0|      1907|            \\N|           \\N|          Drama|\n",
      "|tt0000630|movie|              Hamlet|              Amleto|     0|      1908|            \\N|           \\N|          Drama|\n",
      "|tt0000675|movie|         Don Quijote|         Don Quijote|     0|      1908|            \\N|           \\N|          Drama|\n",
      "|tt0000886|movie|Hamlet, Prince of...|              Hamlet|     0|      1910|            \\N|           \\N|          Drama|\n",
      "|tt0000941|movie|      Locura de amor|      Locura de amor|     0|      1909|            \\N|           45|          Drama|\n",
      "|tt0001049|movie|      Gøngehøvdingen|      Gøngehøvdingen|     0|      1909|            \\N|           \\N|      Drama,War|\n",
      "|tt0001112|movie|              Amleto|              Amleto|     0|      1910|            \\N|           \\N|          Drama|\n",
      "|tt0001175|movie|             Camille|La dame aux camélias|     0|      1912|            \\N|           \\N|  Drama,Romance|\n",
      "|tt0001184|movie|Don Juan de Serra...|Don Juan de Serra...|     0|      1910|            \\N|           58|Adventure,Drama|\n",
      "+---------+-----+--------------------+--------------------+------+----------+--------------+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 9 colunas.\n",
      "O DataFrame tem 238636 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Alterando o nome das colunas\n",
    "\n",
    "basicos_filmes = basicos_filmes.withColumnRenamed(\"tconst\", \"id_filme\") \\\n",
    "        .withColumnRenamed(\"titleType\", \"tipo\") \\\n",
    "        .withColumnRenamed(\"primaryTitle\", \"titulo\") \\\n",
    "        .withColumnRenamed(\"originalTitle\", \"titulo_original\") \\\n",
    "        .withColumnRenamed(\"isAdult\", \"adulto\") \\\n",
    "        .withColumnRenamed(\"startYear\", \"lancamento\") \\\n",
    "        .withColumnRenamed(\"endYear\", \"fim_lancamento\") \\\n",
    "        .withColumnRenamed(\"runtimeMinutes\", \"duracao_filme\") \\\n",
    "        .withColumnRenamed(\"genres\", \"genero\")\n",
    "\n",
    "# Filtrando apenas o tipo com valor MOVIE e apenas o Gênero com valor DRAMA\n",
    "\n",
    "basicos_filmes = basicos_filmes.filter((basicos_filmes[\"tipo\"] == \"movie\") & (basicos_filmes[\"genero\"].contains(\"Drama\")))\n",
    "\n",
    "\n",
    "basicos_filmes.printSchema()\n",
    "basicos_filmes.show(10)\n",
    "contagem_de_dados = basicos_filmes.count()\n",
    "contagem_de_colunas = len(basicos_filmes.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a14bb8-0632-4964-838c-029f3276baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a tabela e exportando o df em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ca3b10f-4b04-4108-9627-9b04a5e68f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram salvos com sucesso como arquivo Parquet.\n"
     ]
    }
   ],
   "source": [
    "# importando datetime para separar os diretórios por dia\n",
    "\n",
    "from datetime import datetime\n",
    "current_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "# Definindo a variável do Output\n",
    "\n",
    "output_path = f\"file:/home/hadoop/imdb/parquet/basico_filmes_drama/{current_date}\"\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "\n",
    "basicos_filmes.coalesce(1).write.saveAsTable(name=\"filmes_basico_drama\",mode=\"overwrite\",path=output_path,format=\"parquet\")\n",
    "\n",
    "print(\"Os dados foram salvos com sucesso como arquivo Parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df6060-0592-4f21-b836-f9daaab6ec87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d6590d-6c93-46cb-b9f0-50dd2ecc6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo e criando o df diretor_escritor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc38448-d0d9-4864-8246-5d8888faa753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b98918-1275-4688-b2e8-59856fc9e488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- directors: string (nullable = true)\n",
      " |-- writers: string (nullable = true)\n",
      "\n",
      "+---------+-------------------+---------+\n",
      "|   tconst|          directors|  writers|\n",
      "+---------+-------------------+---------+\n",
      "|tt0000001|          nm0005690|       \\N|\n",
      "|tt0000002|          nm0721526|       \\N|\n",
      "|tt0000003|          nm0721526|       \\N|\n",
      "|tt0000004|          nm0721526|       \\N|\n",
      "|tt0000005|          nm0005690|       \\N|\n",
      "|tt0000006|          nm0005690|       \\N|\n",
      "|tt0000007|nm0005690,nm0374658|       \\N|\n",
      "|tt0000008|          nm0005690|       \\N|\n",
      "|tt0000009|          nm0085156|nm0085156|\n",
      "|tt0000010|          nm0525910|       \\N|\n",
      "+---------+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 3 colunas.\n",
      "O DataFrame tem 10265844 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "diretor_escritor = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_crew.tsv\")\n",
    "\n",
    "diretor_escritor.printSchema()\n",
    "diretor_escritor.show(10)\n",
    "contagem_de_dados = diretor_escritor.count()\n",
    "contagem_de_colunas = len(diretor_escritor.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b458ff-f480-46b4-b28d-625b91f12899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterando o nome das colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9140b8f-acbd-4749-979b-10dad004394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_filme: string (nullable = true)\n",
      " |-- diretores: string (nullable = true)\n",
      " |-- escritores: string (nullable = true)\n",
      "\n",
      "+---------+-------------------+----------+\n",
      "| id_filme|          diretores|escritores|\n",
      "+---------+-------------------+----------+\n",
      "|tt0000001|          nm0005690|        \\N|\n",
      "|tt0000002|          nm0721526|        \\N|\n",
      "|tt0000003|          nm0721526|        \\N|\n",
      "|tt0000004|          nm0721526|        \\N|\n",
      "|tt0000005|          nm0005690|        \\N|\n",
      "|tt0000006|          nm0005690|        \\N|\n",
      "|tt0000007|nm0005690,nm0374658|        \\N|\n",
      "|tt0000008|          nm0005690|        \\N|\n",
      "|tt0000009|          nm0085156| nm0085156|\n",
      "|tt0000010|          nm0525910|        \\N|\n",
      "+---------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 3 colunas.\n",
      "O DataFrame tem 10265844 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "diretor_escritor = diretor_escritor.withColumnRenamed(\"tconst\", \"id_filme\") \\\n",
    "        .withColumnRenamed(\"directors\", \"diretores\") \\\n",
    "        .withColumnRenamed(\"writers\", \"escritores\") \\\n",
    "        \n",
    "diretor_escritor.printSchema()\n",
    "diretor_escritor.show(10)\n",
    "contagem_de_dados = diretor_escritor.count()\n",
    "contagem_de_colunas = len(diretor_escritor.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf11ba0-fbc8-4b4e-bcf4-949156275b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a tabela e exportando o df em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be195601-eded-4736-a2bc-3cda363f6327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram salvos com sucesso como arquivo Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "# Definindo a variável do Output\n",
    "\n",
    "output_path = f\"file:/home/hadoop/imdb/parquet/diretores_escritores/{current_date}\"\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "\n",
    "diretor_escritor.coalesce(1).write.saveAsTable(name=\"diretor_escritor\",mode=\"overwrite\",path=output_path,format=\"parquet\")\n",
    "\n",
    "print(\"Os dados foram salvos com sucesso como arquivo Parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eddbeb-71f6-4828-9b0f-3c3d19bd55de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd9b6d-ef0f-47b2-a20a-abdbec72ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo e criando o df filmes_principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2620ae-8885-41be-8424-143c6ecf2321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d9f2ef-2bd4-4510-8eaa-6033c70eebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- ordering: string (nullable = true)\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- characters: string (nullable = true)\n",
      "\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|   tconst|ordering|   nconst|       category|                 job|characters|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|tt0000001|       1|nm1588970|           self|                  \\N|  [\"Self\"]|\n",
      "|tt0000001|       2|nm0005690|       director|                  \\N|        \\N|\n",
      "|tt0000001|       3|nm0374658|cinematographer|director of photo...|        \\N|\n",
      "|tt0000002|       1|nm0721526|       director|                  \\N|        \\N|\n",
      "|tt0000002|       2|nm1335271|       composer|                  \\N|        \\N|\n",
      "|tt0000003|       1|nm0721526|       director|                  \\N|        \\N|\n",
      "|tt0000003|       2|nm1770680|       producer|            producer|        \\N|\n",
      "|tt0000003|       3|nm1335271|       composer|                  \\N|        \\N|\n",
      "|tt0000003|       4|nm5442200|         editor|                  \\N|        \\N|\n",
      "|tt0000004|       1|nm0721526|       director|                  \\N|        \\N|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 6 colunas.\n",
      "O DataFrame tem 58797177 linhas (dados).\n"
     ]
    }
   ],
   "source": [
    "filmes_principais = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_principal.tsv\")\n",
    "\n",
    "filmes_principais.printSchema()\n",
    "filmes_principais.show(10)\n",
    "contagem_de_dados = filmes_principais.count()\n",
    "contagem_de_colunas = len(filmes_principais.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f8aa6-2a90-47f2-bc58-0403b69d6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c8195c3-9a67-4d43-ab1b-2181dc5cef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_filme: string (nullable = true)\n",
      " |-- id_nome: string (nullable = true)\n",
      " |-- ordem: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- personagem: string (nullable = true)\n",
      " |-- trabalho: string (nullable = true)\n",
      "\n",
      "+---------+---------+-----+---------------+----------+--------------------+\n",
      "| id_filme|  id_nome|ordem|      categoria|personagem|            trabalho|\n",
      "+---------+---------+-----+---------------+----------+--------------------+\n",
      "|tt0000001|nm1588970|    1|           self|  [\"Self\"]|                  \\N|\n",
      "|tt0000001|nm0005690|    2|       director|        \\N|                  \\N|\n",
      "|tt0000001|nm0374658|    3|cinematographer|        \\N|director of photo...|\n",
      "|tt0000002|nm0721526|    1|       director|        \\N|                  \\N|\n",
      "|tt0000002|nm1335271|    2|       composer|        \\N|                  \\N|\n",
      "|tt0000003|nm0721526|    1|       director|        \\N|                  \\N|\n",
      "|tt0000003|nm1770680|    2|       producer|        \\N|            producer|\n",
      "|tt0000003|nm1335271|    3|       composer|        \\N|                  \\N|\n",
      "|tt0000003|nm5442200|    4|         editor|        \\N|                  \\N|\n",
      "|tt0000004|nm0721526|    1|       director|        \\N|                  \\N|\n",
      "+---------+---------+-----+---------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 6 colunas.\n",
      "O DataFrame tem 58797177 linhas (dados).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "filme_ator = filmes_principais.withColumnRenamed(\"tconst\", \"id_filme\") \\\n",
    "        .withColumnRenamed(\"ordering\", \"ordem\") \\\n",
    "        .withColumnRenamed(\"nconst\", \"id_nome\") \\\n",
    "        .withColumnRenamed(\"category\", \"categoria\") \\\n",
    "        .withColumnRenamed(\"job\", \"trabalho\") \\\n",
    "        .withColumnRenamed(\"characters\", \"personagem\") \\\n",
    "\n",
    "# selecionando a ordem de apresentação das colunas\n",
    "filme_ator = filme_ator.select(col(\"id_filme\"), col(\"id_nome\"), col(\"ordem\"), col(\"categoria\"), col(\"personagem\"), col(\"trabalho\"))\n",
    "\n",
    "\n",
    "filme_ator.printSchema()\n",
    "filme_ator.show(10)\n",
    "contagem_de_dados = filme_ator.count()\n",
    "contagem_de_colunas = len(filme_ator.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec049a0-30ea-47e1-bc11-9cc8006c8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a tabela e exportando o df em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f13cae0-7d50-45cd-a573-670a6493f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram salvos com sucesso como arquivo Parquet.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "# Definindo a variável do Output\n",
    "\n",
    "output_path = f\"file:/home/hadoop/imdb/parquet/filme_ator/{current_date}\"\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "\n",
    "filme_ator.coalesce(1).write.saveAsTable(name=\"filmes_atores\",mode=\"overwrite\",path=output_path,format=\"parquet\")\n",
    "\n",
    "print(\"Os dados foram salvos com sucesso como arquivo Parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3955a53-178c-47e6-a77a-97a4c7377089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8d9c1-e800-446a-af3f-a3d75d188970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo e criando o df filmes_votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f5c6e-d959-44b1-ab7e-3e7450c1dfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31b5cedc-5d3a-45e8-8c82-9ed827a9b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- averageRating: string (nullable = true)\n",
      " |-- numVotes: string (nullable = true)\n",
      "\n",
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.7|    2003|\n",
      "|tt0000002|          5.8|     269|\n",
      "|tt0000003|          6.5|    1898|\n",
      "|tt0000004|          5.5|     178|\n",
      "|tt0000005|          6.2|    2682|\n",
      "|tt0000006|          5.0|     183|\n",
      "|tt0000007|          5.4|     839|\n",
      "|tt0000008|          5.4|    2147|\n",
      "|tt0000009|          5.3|     207|\n",
      "|tt0000010|          6.9|    7331|\n",
      "+---------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 3 colunas.\n",
      "O DataFrame tem 1363146 linhas (dados).\n",
      "O DataFrame tem 1.36 milhões de linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filmes_votos = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/title_rating.tsv\")\n",
    "\n",
    "filmes_votos.printSchema()\n",
    "filmes_votos.show(10)\n",
    "contagem_de_dados = filmes_votos.count()\n",
    "contagem_de_colunas = len(filmes_votos.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")\n",
    "\n",
    "# contagem de linhas, 1e6 é a notação científica para um milhão\n",
    "milhoes_de_linhas = contagem_de_dados / 1e6\n",
    "print(f\"O DataFrame tem {milhoes_de_linhas:.2f} milhões de linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0bcff-d390-4b07-9408-5a1fb131750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1b19ce5-9029-488b-a280-54a7140f3ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_filme: string (nullable = true)\n",
      " |-- avaliacao_media: string (nullable = true)\n",
      " |-- total_votos: string (nullable = true)\n",
      "\n",
      "+---------+---------------+-----------+\n",
      "| id_filme|avaliacao_media|total_votos|\n",
      "+---------+---------------+-----------+\n",
      "|tt0000001|            5.7|       2003|\n",
      "|tt0000002|            5.8|        269|\n",
      "|tt0000003|            6.5|       1898|\n",
      "|tt0000004|            5.5|        178|\n",
      "|tt0000005|            6.2|       2682|\n",
      "|tt0000006|            5.0|        183|\n",
      "|tt0000007|            5.4|        839|\n",
      "|tt0000008|            5.4|       2147|\n",
      "|tt0000009|            5.3|        207|\n",
      "|tt0000010|            6.9|       7331|\n",
      "+---------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 3 colunas.\n",
      "O DataFrame tem 1363146 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "filmes_votos = filmes_votos.withColumnRenamed(\"tconst\", \"id_filme\") \\\n",
    "        .withColumnRenamed(\"averageRating\", \"avaliacao_media\") \\\n",
    "        .withColumnRenamed(\"numVotes\", \"total_votos\") \\\n",
    "\n",
    "filmes_votos.printSchema()\n",
    "filmes_votos.show(10)\n",
    "contagem_de_dados = filmes_votos.count()\n",
    "contagem_de_colunas = len(filmes_votos.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aba35b-9c93-445b-a4f9-c7c8827eea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a tabela e exportando o df em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58c205ea-ffbd-40d4-9b37-d56a7f0865f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram salvos com sucesso como arquivo Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "# Definindo a variável do Output\n",
    "\n",
    "output_path = f\"file:/home/hadoop/imdb/parquet/filmes_votos/{current_date}\"\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "\n",
    "filmes_votos.coalesce(1).write.saveAsTable(name=\"filmes_votos\",mode=\"overwrite\",path=output_path,format=\"parquet\")\n",
    "\n",
    "print(\"Os dados foram salvos com sucesso como arquivo Parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d153e-0c25-4776-8923-326e4447b9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c9e0f-d20f-4217-b42e-17e21ba03c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o df nomes_colaboradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21cbdf-d9a9-44eb-9588-98ef0334a115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d47b23b-9ec3-4100-af3d-7224000ea2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: string (nullable = true)\n",
      " |-- deathYear: string (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      "\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0072308,tt00319...|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0038355,tt01170...|\n",
      "|nm0000003|Brigitte Bardot|     1934|       \\N|actress,soundtrac...|tt0054452,tt00564...|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,soundtrack,...|tt0072562,tt00804...|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00839...|\n",
      "|nm0000006| Ingrid Bergman|     1915|     1982|actress,soundtrac...|tt0034583,tt00368...|\n",
      "|nm0000007|Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0042593,tt00432...|\n",
      "|nm0000008|  Marlon Brando|     1924|     2004|actor,soundtrack,...|tt0078788,tt00708...|\n",
      "|nm0000009| Richard Burton|     1925|     1984|actor,soundtrack,...|tt0061184,tt00578...|\n",
      "|nm0000010|   James Cagney|     1899|     1986|actor,soundtrack,...|tt0029870,tt00420...|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 6 colunas.\n",
      "O DataFrame tem 12954255 linhas (dados).\n",
      "O DataFrame tem 12.95 milhões de linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nome_colaboradores = spark.read.option(\"delimiter\", \"\\t\").option(\"header\", \"true\").csv(\"file:/home/hadoop/imdb/name.tsv\")\n",
    "\n",
    "nome_colaboradores.printSchema()\n",
    "nome_colaboradores.show(10)\n",
    "contagem_de_dados = nome_colaboradores.count()\n",
    "contagem_de_colunas = len(nome_colaboradores.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")\n",
    "\n",
    "# contagem de linhas, 1e6 é a notação científica para um milhão\n",
    "milhoes_de_linhas = contagem_de_dados / 1e6\n",
    "print(f\"O DataFrame tem {milhoes_de_linhas:.2f} milhões de linhas (dados).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a218b-900d-422b-95b6-02d13a88e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o nome das colunas, a ordem e um novo valor para nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c9f022f-ee9c-4fb0-8dc8-b6bb2998f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_nome: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- participacao_filmes: string (nullable = true)\n",
      " |-- profissao_principal: string (nullable = true)\n",
      " |-- ano_nascimento: string (nullable = true)\n",
      " |-- ano_falecimento: string (nullable = true)\n",
      "\n",
      "+---------+---------------+--------------------+--------------------+--------------+---------------+\n",
      "|  id_nome|           nome| participacao_filmes| profissao_principal|ano_nascimento|ano_falecimento|\n",
      "+---------+---------------+--------------------+--------------------+--------------+---------------+\n",
      "|nm0000001|   Fred Astaire|tt0072308,tt00319...|soundtrack,actor,...|          1899|           1987|\n",
      "|nm0000002|  Lauren Bacall|tt0038355,tt01170...|  actress,soundtrack|          1924|           2014|\n",
      "|nm0000003|Brigitte Bardot|tt0054452,tt00564...|actress,soundtrac...|          1934|        vivo(a)|\n",
      "|nm0000004|   John Belushi|tt0072562,tt00804...|actor,soundtrack,...|          1949|           1982|\n",
      "|nm0000005| Ingmar Bergman|tt0050986,tt00839...|writer,director,a...|          1918|           2007|\n",
      "|nm0000006| Ingrid Bergman|tt0034583,tt00368...|actress,soundtrac...|          1915|           1982|\n",
      "|nm0000007|Humphrey Bogart|tt0042593,tt00432...|actor,soundtrack,...|          1899|           1957|\n",
      "|nm0000008|  Marlon Brando|tt0078788,tt00708...|actor,soundtrack,...|          1924|           2004|\n",
      "|nm0000009| Richard Burton|tt0061184,tt00578...|actor,soundtrack,...|          1925|           1984|\n",
      "|nm0000010|   James Cagney|tt0029870,tt00420...|actor,soundtrack,...|          1899|           1986|\n",
      "+---------+---------------+--------------------+--------------------+--------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:======================================>                  (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame tem 6 colunas.\n",
      "O DataFrame tem 12954255 linhas (dados).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "info_colaboradores = nome_colaboradores.withColumnRenamed(\"nconst\", \"id_nome\") \\\n",
    "        .withColumnRenamed(\"primaryName\", \"nome\") \\\n",
    "        .withColumnRenamed(\"birthYear\", \"ano_nascimento\") \\\n",
    "        .withColumnRenamed(\"deathYear\", \"ano_falecimento\") \\\n",
    "        .withColumnRenamed(\"primaryProfession\", \"profissao_principal\") \\\n",
    "        .withColumnRenamed(\"knownForTitles\", \"participacao_filmes\") \\\n",
    "\n",
    "info_colaboradores = info_colaboradores.select(col(\"id_nome\"), col(\"nome\"), col(\"participacao_filmes\"), col(\"profissao_principal\"), col(\"ano_nascimento\"), col(\"ano_falecimento\"))\n",
    "\n",
    "# usar \\\\N para garantir que o caractere \\ seja interpretado literalmente\n",
    "info_colaboradores = info_colaboradores.withColumn(\"ano_falecimento\", when(col(\"ano_falecimento\") == \"\\\\N\", \"vivo(a)\").otherwise(col(\"ano_falecimento\")))\n",
    "\n",
    "info_colaboradores.printSchema()\n",
    "info_colaboradores.show(10)\n",
    "contagem_de_dados = info_colaboradores.count()\n",
    "contagem_de_colunas = len(info_colaboradores.columns)\n",
    "\n",
    "# contagem de colunas\n",
    "print(f\"O DataFrame tem {contagem_de_colunas} colunas.\")\n",
    "\n",
    "# contagem de linhas\n",
    "print(f\"O DataFrame tem {contagem_de_dados} linhas (dados).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80645cd3-a450-479a-9aca-33d9b01a635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando a tabela e exportando o df em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c36b0594-8c06-46fc-8cce-8431602b0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados foram salvos com sucesso como arquivo Parquet.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "# Definindo a variável do Output\n",
    "\n",
    "output_path = f\"file:/home/hadoop/imdb/parquet/info_colaboradores/{current_date}\"\n",
    "\n",
    "# Salvar o DataFrame como um arquivo Parquet\n",
    "\n",
    "info_colaboradores.coalesce(1).write.saveAsTable(name=\"colaboradores_filmes\",mode=\"overwrite\",path=output_path,format=\"parquet\")\n",
    "\n",
    "print(\"Os dados foram salvos com sucesso como arquivo Parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956f8df-19ba-48ad-a4a5-ba18aee18c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7455d57-86b0-490d-95a2-65d67b7890f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad6cd20-f02a-4bcb-8bef-5b594451cdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b11c5-4ea3-420f-bbd4-48ab890898d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff083475-b35b-4742-aa0c-23b1906033ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a959197-18ab-4489-90e2-53f067e0d460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60370a7a-09d3-41d8-a1b3-7f8807d26c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfe659-b7b6-42a1-80f9-25df26cb8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar depois esse codigo: \n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Substitua \"\\N\" por \"adaptado\" na coluna \"escritores\"\n",
    "diretor_escritor = diretor_escritor.withColumn(\"escritores\", when(col(\"escritores\") == \"\\\\N\", \"adaptado\").otherwise(col(\"escritores\")))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
